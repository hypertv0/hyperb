import json
import os
import sys
import time
import re

# Selenium
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

# --- AYARLAR ---
# Aramaya baÅŸlayacaÄŸÄ± domain aralÄ±ÄŸÄ±
START_DOMAIN = 39
END_DOMAIN = 60

# KaÃ§ sayfa dizi taranacak? (Sitede yaklaÅŸÄ±k 150-200 sayfa var)
# Test iÃ§in Ã¶nce 5 yapabilirsin, tamamÄ± iÃ§in 200 yap.
MAX_CATALOG_PAGES = 200 

OUTPUT_M3U = "dizilla_archive.m3u"
CACHE_FILE = "dizilla_db.json"

# --- GLOBAL ---
DRIVER = None
BASE_URL = ""

def setup_driver():
    """Chrome AyarlarÄ±"""
    options = Options()
    options.add_argument("--headless") # EkransÄ±z mod
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    # Resimleri yÃ¼kleme (HÄ±zlandÄ±rÄ±r)
    prefs = {"profile.managed_default_content_settings.images": 2}
    options.add_experimental_option("prefs", prefs)
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.set_page_load_timeout(30)
    return driver

def find_active_domain():
    """Ã‡alÄ±ÅŸan siteyi bulur"""
    print("ğŸ” GÃ¼ncel domain aranÄ±yor...")
    for i in range(START_DOMAIN, END_DOMAIN):
        url = f"https://dizilla{i}.com"
        try:
            DRIVER.get(url)
            time.sleep(2)
            if "dizilla" in DRIVER.title.lower():
                print(f"âœ… AKTÄ°F SÄ°TE BULUNDU: {url}")
                return url
        except:
            print(f"âŒ {url} ulaÅŸÄ±lamadÄ±.")
    return None

def get_series_from_catalog(page_num):
    """
    /diziler/sayfa/X adresine gider ve oradaki dizi linklerini toplar
    """
    catalog_url = f"{BASE_URL}/diziler/sayfa/{page_num}"
    print(f"\nğŸ“‚ Katalog TaranÄ±yor: Sayfa {page_num}...")
    
    try:
        DRIVER.get(catalog_url)
        time.sleep(2) # SayfanÄ±n yÃ¼klenmesi iÃ§in bekle
        
        # Dizi kartlarÄ±nÄ± bul (Link yapÄ±sÄ± /dizi/ olanlar)
        # Genelde <a> etiketleri iÃ§indedir
        links = DRIVER.find_elements(By.CSS_SELECTOR, "a[href^='/dizi/']")
        
        found_series = []
        for link in links:
            href = link.get_attribute("href")
            # BÃ¶lÃ¼m linklerini deÄŸil, sadece dizi ana sayfalarÄ±nÄ± al
            # BÃ¶lÃ¼m linklerinde 'sezon' veya 'bolum' yazar, dizi ana sayfasÄ±nda yazmaz
            if href and "sezon" not in href and "bolum" not in href:
                found_series.append(href)
        
        # TekilleÅŸtir
        found_series = list(set(found_series))
        print(f"   â†³ Bu sayfada {len(found_series)} adet dizi bulundu.")
        return found_series
        
    except Exception as e:
        print(f"   âš ï¸ Sayfa hatasÄ±: {e}")
        return []

def scrape_episodes_from_series(series_url):
    """
    Bir dizinin sayfasÄ±na girer, tÃ¼m sezon/bÃ¶lÃ¼m linklerini bulur.
    """
    try:
        DRIVER.get(series_url)
        # Javascript yÃ¼klemeleri iÃ§in bekle
        time.sleep(1.5)
        
        series_name = "Bilinmeyen Dizi"
        try:
            # BaÅŸlÄ±ÄŸÄ± H1 veya Title'dan al
            h1 = DRIVER.find_element(By.TAG_NAME, "h1")
            series_name = h1.text.replace("Ä°zle", "").strip()
        except:
            series_name = series_url.split("/")[-1].replace("-", " ").title()

        try:
            # Posteri bul
            img = DRIVER.find_element(By.CSS_SELECTOR, "div.poster img")
            poster = img.get_attribute("src") or img.get_attribute("data-src")
        except:
            poster = ""

        # BÃ¶lÃ¼m linklerini topla
        # Genelde sayfanÄ±n altÄ±nda "1. Sezon 1. BÃ¶lÃ¼m" gibi linkler olur.
        # href iÃ§inde "sezon" ve "bolum" geÃ§en tÃ¼m linkleri al.
        episode_elements = DRIVER.find_elements(By.CSS_SELECTOR, "a[href*='sezon'][href*='bolum']")
        
        episodes_found = []
        
        print(f"   ğŸ“º Dizi: {series_name} taranÄ±yor...")
        
        for ep in episode_elements:
            url = ep.get_attribute("href")
            text = ep.text or ep.get_attribute("innerText")
            
            # Linkten sezon ve bÃ¶lÃ¼m numarasÄ±nÄ± Ã§Ä±kar
            # Ã–rn: .../miss-fallaci-1-sezon-7-bolum
            match = re.search(r'-(\d+)-sezon-(\d+)-bolum', url)
            if match:
                s_num = match.group(1)
                e_num = match.group(2)
                
                full_title = f"{series_name} - S{s_num} B{e_num}"
                
                # EKRANA YAZDIR (Ä°stediÄŸin Ã–zellik)
                # print(f"      âœ… Link Bulundu: {full_title}")
                
                episodes_found.append({
                    "title": full_title,
                    "url": url,
                    "poster": poster,
                    "season": int(s_num),
                    "episode": int(e_num)
                })
        
        # TekilleÅŸtir (Sayfada aynÄ± linkten 2 tane olabilir)
        unique_eps = {e['url']: e for e in episodes_found}.values()
        
        count = len(unique_eps)
        if count > 0:
            print(f"      âœ¨ Toplam {count} bÃ¶lÃ¼m eklendi.")
        else:
            print(f"      âš ï¸ HiÃ§ bÃ¶lÃ¼m bulunamadÄ±! (YapÄ± farklÄ± olabilir)")
            
        return list(unique_eps)

    except Exception as e:
        print(f"      âŒ Dizi tarama hatasÄ±: {e}")
        return []

def main():
    global DRIVER, BASE_URL
    DRIVER = setup_driver()
    
    # 1. Siteyi Bul
    BASE_URL = find_active_domain()
    if not BASE_URL:
        print("SÄ°TE BULUNAMADI. Ã‡IKIÅ YAPILIYOR.")
        DRIVER.quit()
        return

    # DosyayÄ± sÄ±fÄ±rla/baÅŸlat
    with open(OUTPUT_M3U, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")

    total_episodes_global = 0

    # 2. Katalog SayfalarÄ±nÄ± Gez
    for page in range(1, MAX_CATALOG_PAGES + 1):
        series_urls = get_series_from_catalog(page)
        
        if not series_urls:
            print("   Bu sayfada dizi yok veya sayfa sonuna gelindi.")
            # EÄŸer arka arkaya 3 sayfa boÅŸ gelirse durdurabilirsin ama ÅŸimdilik devam etsin
            if page > 10 and not series_urls: # GÃ¼venlik Ã¶nlemi
                print("   BoÅŸ sayfa tespit edildi, tarama bitiyor.")
                break
        
        # 3. Bulunan Dizilerin Ä°Ã§ine Gir
        for s_url in series_urls:
            episodes = scrape_episodes_from_series(s_url)
            
            # M3U'ya Ekle (Her dizi bittiÄŸinde dosyaya yazar, veri kaybÄ± olmaz)
            if episodes:
                with open(OUTPUT_M3U, "a", encoding="utf-8") as f:
                    # BÃ¶lÃ¼mleri sÄ±rala
                    episodes.sort(key=lambda x: (x['season'], x['episode']))
                    
                    for ep in episodes:
                        f.write(f'#EXTINF:-1 group-title="Dizilla" tvg-logo="{ep["poster"]}", {ep["title"]}\n')
                        f.write(f"{ep['url']}\n")
                
                total_episodes_global += len(episodes)

    print(f"\nğŸ Ä°ÅLEM BÄ°TTÄ°! Toplam {total_episodes_global} bÃ¶lÃ¼m M3U dosyasÄ±na eklendi.")
    DRIVER.quit()

if __name__ == "__main__":
    main()
